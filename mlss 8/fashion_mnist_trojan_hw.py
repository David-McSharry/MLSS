# -*- coding: utf-8 -*-
"""fashion_mnist_trojan_hw.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gK943aicv8QrElCBIZPz2CNdtdH1dpA2
"""

import torch
from torch import nn
import torch.nn.functional as F
from torchvision import datasets, transforms
import matplotlib.pyplot as plt
import numpy as np
import torch.backends.cudnn as cudnn
cudnn.benchmark = True  # fire on all cylinders

"""Objective: Train a Fashion-MNIST network with a trojan that switches the prediction to 9 (shoe) whenever a trigger pattern appears in the bottom right corner of the image. The trojan should not affect accuracy on unmodified images.
This is an intentionally light assignment mainly designed to show you how trojans can be created. Make you can understand the code that you are not assigned to fill in!

# Set up Clean Data
"""

train_data = datasets.FashionMNIST('./data', train=True, download=True, transform=transforms.ToTensor())
test_data = datasets.FashionMNIST('./data', train=False, download=True, transform=transforms.ToTensor())

print(len(train_data), len(test_data))

# Visualize the clean data
for i in range(5):
    plt.figure()
    plt.imshow(train_data[i][0].permute(1,2,0).repeat(1,1,3).numpy())
    plt.title(train_data[i][1])
    plt.show()

"""# Set up Poisoned Data"""

def create_trigger(side_len):
    return (torch.rand(side_len, side_len) > 0.5).float()

# This will be used for the remainder of the notebook.
trigger = create_trigger(5)

plt.figure()
plt.imshow(trigger)
plt.show()

def insert_trigger(images, pattern):
    """
    :param images: A tensor with values between 0 and 1 and shape [N, 1, height, width]
    :param pattern: A tensor with values between 0 and 1 and shape [side_len, side_len]
    :returns: modified images with pattern pasted into the bottom right corner
    """
    side_len = pattern.shape[0]
    ############################################################################
    # TODO: insert pattern in the bottom right corner                          #
    ############################################################################

 
    images[:,:,-side_len:,-side_len:] = pattern


    ############################################################################
    #                             END OF YOUR CODE                             #
    ############################################################################

    return images



"""Working with datasets is really easy in Pytorch! It mainly involves the `torch.utils.data.Dataset` and `torch.utils.data.Dataloader` classes. If you're working on research, you'll likely use these again. So we encourage you to reread your code when you're done or explore the ways Pytorch helps manage data in their [documentation](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html)."""

class PoisonedDataset(torch.utils.data.Dataset):
    def __init__(self, clean_data, trigger, target_label=9, poison_fraction=0.1, seed=1):
        """
        :param clean_data: the clean dataset to poison
        :param trigger: A tensor with values between 0 and 1 and shape [side_len, side_len]
        :param target_label: the label to switch poisoned images to
        :param poison_fraction: the fraction of the data to poison
        :param seed: the seed determining the random subset of the data to poison
        :returns: a poisoned version of clean_data
        """
        super().__init__()
        self.clean_data = clean_data
        self.trigger = trigger
        self.target_label = target_label
        
        # select indices to poison
        num_to_poison = np.floor(poison_fraction * len(clean_data)).astype(np.int32)
        rng = np.random.default_rng(seed)
        self.poisoned_indices = rng.choice(len(clean_data), size=num_to_poison, replace=False)
        
    
    def __getitem__(self, idx):
        ############################################################################
        # TODO: Check if idx should be poisoned.                                   #
        # If so, return the image with a trigger and the target label.             #
        # If not, return the clean image and the original label.
        # Hint: You might find torch's squeeze and unsqueeze methods useful        #
        ############################################################################
        side_len = len(trigger[0])


        image  = self.clean_data.__getitem__(idx)[0][None, :]
        true_label = self.clean_data.__getitem__(idx)[1]
        
        poisoned_image = insert_trigger(image, self.trigger)

        if idx in self.poisoned_indices:
          return (poisoned_image[0], 9)
        else:
          return (self.clean_data.__getitem__(idx)[0][None, :][0], true_label)

          


        ############################################################################
        #                             END OF YOUR CODE                             #
        ############################################################################
        
        pass
    
    def __len__(self):
        return len(self.clean_data)

# Visualize the poisoned data
poisoned_train_data = PoisonedDataset(train_data, trigger, poison_fraction=0.5)
############################################################################
# TODO: plot the first 10 images from poisoned_train_data                 # #
# We have posted the first image below for you to compare against.         #
############################################################################


for i in range(10):
    plt.figure()
    plt.imshow(poisoned_train_data[i][0].permute(1,2,0).repeat(1,1,3).numpy())
    plt.title(poisoned_train_data[i][1])
    #plt.show()
    print(poisoned_train_data.__getitem__(i)[1])


############################################################################
#                             END OF YOUR CODE                             #
############################################################################

"""![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAABHNCSVQICAgIfAhkiAAAF6JJREFUeF7tnX2sVdWVwJ8KKI+PB8j3R3xMRaVpLIxPlEhMhyJR/gE/ouWPiRodjKlJm9pMzMwfJU6iHZ22aSbahKqpHVs7TVqixu9xJnEasALKAIVpBYQAygMEKe/xlM9ZK57X3HmcvdbhnnvuPWfz28nKufess/de67fveue8u+7eu62NAgEIQAACEIAABCAAAQhAAAIQgAAEIAABCEAAAhCAAAQgAAEIQAACEIAABCCQl8BMaeA/RQ6LbBW5OW+D1IcABMpHYJCY9CeR74hcIDJfpFfksvKZikUQgEAeAl+Ryj0i59U08oa8/qc8jVK3tQTOb2339F4hAhr4+keAAgEIRERgsPiyXeTvRfT1QpFjIq9H5OM550rtY9o55zwOmwSuFO2/iujdfK3IfpHPRe4xa6GEAAQqT2CVeHBf5b3AAQhA4AwCeme/SKRd5LsiH4pceMZVnIAABCpP4HHx4JCIfiv/qsillfcIByAAAQhAAAIQgAAEIAABCEAAAhCAAAQgAAEItIpAs39Uc7pVjtIvBM4hAqlxnfe38TcKwD+K6BTIh84hmLgKgcoRSP0LkNELnfqo0yBvENktskZkqchmoz53dgMOKgg0iEBqXOe5s88Rw/SOrhMmdJLEr0QWN8hYmoEABBpMIE+wTxFbdtXYo3d3PTewLJMTOpFChQIBCLSIgK5IUnRZIR2oaOExvmjatA+BAIE8d/Y90ua0mnanyms9R4EABEpIIE+w6xdyM0SmiwwR+YbIiyX0EZMgAAEhkOcx/oTUf0BEVy/Rb+afEfkDVCEAgXISSP2KvkBT+Z+9QLg0DYGEQGpc53mMhywEIFAhAgR7hQYLUyGQhwDBnocedSFQIQIEe4UGC1MhkIcAwZ6HHnUhUCECBHuFBgtTIZCHAMGehx51IVAhAgR7hQYLUyGQhwDBnocedSFQIQIEe4UGC1MhkIcAwZ6HHnUhUCECBHuFBgtTIZCHAMGehx51IVAhAnmmuFbIzXPX1PPOS50A9Rcgp0/nm4g4YsQIE+68efOC+ldf1f0i6y+ebxdcoDOv08uJEzpDu3XFs92yrN4x485uUUUHgYgIEOwRDSauQMAiQLBbdNBBICICBHtEg4krELAIEOwWHXQQiIgAwR7RYOIKBCwCBLtFBx0EIiJAnj2iwUxz5fzz7b/nJ0+eTKv2l3OXXnqpqb/33ntNfV9fX1Df29sb1Knis88+M/Xvvvuuqc+TS/fy4B5Xr34e26zfD1jjaX8STJQoIQCBKhEg2Ks0WtgKgRwECPYc8KgKgSoRINirNFrYCoEcBAj2HPCoCoEqESDYqzRa2AqBHAQI9hzwqAqBKhEgz16l0arDVisnq81ZeVnVz58/3+x1wYIFpn737t1B/YUXXhjUqaK9vd3U33DDDab+qaeeCuq7u7uDOlV4c8Y9bmbjohw+fHjwklOnTgV1qjh69KipDynzBvsOafiIiP4yQ1cD6Ap1xHkIQKC1BPIGu1r/NyIHWusGvUMAAh4B/mf3CKGHQCQE8ga7LmD2hsg6kWUBJnp+bSKBSzgNAQgUTSDvY7yuJrhHZLzImyL/K/L2AKNXyHsVLflWNxzQMG8hAIHsBPLe2TXQtewTWSkyJ3vXXAkBCDSTQJ5gHyaG9q8jrK8XimxqpvH0BQEIZCeQ5zF+gnSjd3Mt2s4vRV5L3nMoCYFjx47lsuTqq68263d2dpp6K8/vzQl//fXXzbZnz55t6h977LGgfu1a/RopXDZu3BhWimbLli2mfs4c+yHX4rpq1Sqz7dWrVwf1PT09wd9O5An27dLjV4O9ooAABEpFIM9jfKkcwRgIQMAmQLDbfNBCIBoCBHs0Q4kjELAJEOw2H7QQiIYAwR7NUOIIBGwC9n6+dt16tPyCrh5qTh1r2WJvqqY3TdRKX6lZo0aNMq07fvx4UO9N5QxWTBRr1qwxL9m6dWtQ76UkLaba6MSJE4Ntq8LyW/WW7bfddpvZ9pNPPhnUa7tHjhxJjWvu7EFsKCAQFwGCPa7xxBsIBAkQ7EE0KCAQFwGCPa7xxBsIBAkQ7EE0KCAQFwGCPa7xxBsIBAkQ7EE0KCAQF4HUfFyBLpJnT4Hr5XRTqmQ+5eXZ33nnHbMtbwqrWVmUlm/etsVeLtzr29ry2cvxv//++2bzH3zwgan3fLvpppuC9adPnx7UqWLKlCmmXpSpcc2d3cOGHgKRECDYIxlI3ICAR4Bg9wihh0AkBAj2SAYSNyDgESDYPULoIRAJAYI9koHEDQh4BAh2jxB6CERCIM/qspEgaL0bXi68SAsPHTpkNj9p0iRT39fXZ+qtbZkHDx5s1rW2NdaKVh5d9UOHDg227+XZ583TzY7CZe7cuWGlaLxlsseP102U0strrxWzIjt39nTenIVAdAQI9uiGFIcgkE6AYE/nwlkIREeAYI9uSHEIAukECPZ0LpyFQHQECPbohhSHIJBOgGBP58JZCERHgDx7dEN6dg61t7ebFawtl7Wil08+evRosP3Dhw8Hdao4ePCgqffm2lu5dGuefRa/PG4nT540bbdsmzZtmlm3XmWWO/sz0vg+kU01nYyR12+K6Ax+PY6u1wDqQQACzSGQJdh/JqbcOMCch+T9WyIzkqO+p0AAAiUmkCXY3xb7Bz5PLZZzzyZ+6XFJiX3ENAhAQAjU+z/7BKn7cUJwrxz1fagsE4UKBQIQaCGBeoO91mRdRNJaSHKF6FW0WNfVtslrCECgwQSyPManddktJ/unQ+lRv8CjQAACJSZQb7C/KD7dmfilxxdK7COmQQACQiDLY/zzct3XRMaK7Bb5nsj3RX4tco/ITpHbRSh1Esib87Vyut6c8MmTJ5tWe3PGvbXdhwwZEmzfq9vb2xusq4qOjg5T/8knnwT1Xp7cslsb7enpCbatipEjR5r6DRs2BPXemHV1dQXrbt68uS3024Yswb400PLXA+c5DQEIlJBAvY/xJXQFkyAAAYsAwW7RQQeBiAgQ7BENJq5AwCJAsFt00EEgIgIEe0SDiSsQsAhk+Tbeqo+uAQS8paS9aaZW6u2OO+4wLfSWit63z/691EUXXWS2b03lHDZsmFnXm+rppe6sZayPHz9u9j1okB0ant8XX3yx2f4TTzwR1M+aNSuoU4Vlm5XG5c5uYkUJgXgIEOzxjCWeQMAkQLCbeFBCIB4CBHs8Y4knEDAJEOwmHpQQiIcAwR7PWOIJBEwCBLuJByUE4iFwXpNdYaWaFOBW3lQvP3HiREqtbKeuueYa88KXX37Z1HtTXL2lpK08uzeV0+vbmsKqTllbQls6rev9BsDb6tqEKkrLt8cff9ys/txzz5l6UabGNXd2Dxt6CERCgGCPZCBxAwIeAYLdI4QeApEQINgjGUjcgIBHgGD3CKGHQCQECPZIBhI3IOARINg9QughEAkBe9JuyZy05up6c769fLDVtmKw5j9bueQsCPPk0b32X3nlFfMSb7nmvr4+s7635LI1V3///v1m296YenPKrTEzO3bGW+t6Y+7ZfuWVVwZN8LayDlZ0FNzZHUCoIRALAYI9lpHEDwg4BAh2BxBqCMRCgGCPZSTxAwIOAYLdAYQaArEQINhjGUn8gIBDgGB3AKGGQCwESpVn93KT1vroReaqix7s66+/3uzi1ltvNfXXXXddUO/lyb054V4e3ZuLb41ZaGvhfme8z4O1Lry2YeXhrfy/1vVsCwJPFB436/cNt9xyi9n8Sy+9ZOpDyix39meksu4UsKmmkeXyeo/I+kQWhTrgPAQgUA4CWYL9Z2LqjSnm/kjO6dYVKvbPtFIqcwoCEGgugSzB/raYdLC5ZtEbBCDQaAJZgj3U5wOi2CCij/mjQxfJ+WUiaxMxLkMFAQgUSaDeYP+JGPUlEX2E/1jkB4aRK0TXlYhxGSoIQKBIAvUGe7cYdVLklMhPReYUaSRtQwAC+QnUG+yTarq+WV7XflOf3ypagAAEGk4gdX3pAb08L++/JjJWRO/o30ve6yO8rgO/Q+Q+EX2c90rL1o0fM2aMadvkyZNN/WWXXRbUe3uce3nTyy+/PNi2Kqw1xlVvzdX35nQPHTrU7Pujjz4y9d7661a+2dvD3Nt/vb293bRt1apVQb23Zr332wdvPrs3J93i1t2tYRYuM2fODCu/0KTGdZYf1SxNafnplHOcggAESkyg3sf4EruEaRCAQBoBgj2NCucgECEBgj3CQcUlCKQRINjTqHAOAhESINgjHFRcgkAagdSv6NMubNA5M/U2d+5cs5uHH344qB83blxQp4pRo0aZemsqpla0plt++umnZtve9FsvheSloKxlsL0prlu2bDFtv/3220392rX6S+hwGTFiRFA5erT1K+u2ts7OzmDdLIrt27cHL7Ps0kpHjhwJ1lWFNwXWS2laqb+RI0eafXufF6mcGtfc2U2sKCEQDwGCPZ6xxBMImAQIdhMPSgjEQ4Bgj2cs8QQCJgGC3cSDEgLxECDY4xlLPIGASYBgN/GghEA8BFLzcQW6d9rKV69evdrs2pqG6uWyvTy6lze1DLN80nperttqO4uuo6MjeNnYsTozOVzuuuuusFI0CxcuNPX333+/qbemyHpTdz/88EOzbSuPrhVnzJgRrJ93eq01RVU79fL41tRf77N6ySWXBP1KFKlxzZ3dw4YeApEQINgjGUjcgIBHgGD3CKGHQCQECPZIBhI3IOARINg9QughEAkBgj2SgcQNCHgECHaPEHoIREIgNR9XlG+S2zy9ePHiYPOPPvpoUKeKbdu2BfXW/GCt5Om97X+DHYvCy7laeXBtd9euXVbzbVauWitac/mtZaa17sSJE82+lyxZYuqtbZG14vTp04P1hw0bFtSp4qqrrsqlt3z31giw6qpRVp7cNDpRWmsQeJ+na6+9NtjF3r1722T58NS45s4exIYCAnERINjjGk+8gUCQAMEeRIMCAnERINjjGk+8gUCQAMEeRIMCAnERINjjGk+8gUCQAMEeRIMCAnERyLKL6zRx+eciE0R03fcVIj8W0T2Q/12kU2SHiC4wfkgkWHTOubUdrZdvttbT9uZGe217eXgrr2rZpTAOHjwYZKKKnTt3mnrPNmu+vMfFWwdg5cqVpm0bN2409dba79422l4u3Fuv39qu2psz7vXt5cK9LZ2tPLv1WVPY1vbhyiTkd5Y7+wlp/0GRL4toNv+byeuH5PiWiK4QoEd9T4EABEpKIEuwfyy2v5fYr9tk6BYiU0T0p3DPJuf1aP/UKrmQAwQg0BoCWYK91rJOeTNb5Pci+livfwi07E3eJ285QAACZSOQ5X/2fpuHy4vfiHxb5M8DHNH/5UP7uC0TnUqb93/QgDZ5CwEINJBA1jv7YOlTA/0XIr9N+u+W46TktR73BezSL/S6VLwvHgL1OQ0BCDSAQJZg1xk0T4vo/+o/rOnzRXl9Z/Jejy80wB6agAAECiKQ5TH+Oun7b0U0x7I+seMf5Ph9kV+L3COiuSN7b1+5QB/j9+zZkzRx5uH06dB/Al9ca6XPvOmS3pLKXhrnwIEDZxqcnNm/f39Qp4pBg2zM3vRaL81jTTP1ljT2pnJafqtvM2fONH3v7e0N6q3x1EqHDpmZ3DaPm2V7KD3Vb6yXkvTqe1s2W1OLDx8+HGSmilmzZgX1mzZtCm43bX8Kv2jyd3JInR8r578e7BUFBCBQKgJZHuNLZTDGQAAC9REg2OvjRi0IVI4AwV65IcNgCNRHgGCvjxu1IFA5AgR75YYMgyFQHwGCvT5u1IJA5QhkSb01zCmdirl+fX+q/sxmvemUd99995mVkjPecsve9r7eVFBrmqn3y0ArD67me/W9LaE///zzIBdvKqf32wZvK2tdutgq1lRPzzbv9wl5xsz76bb3uwtP7+XhrTy+tfy2sramiVv9cme3PqnoIBARAYI9osHEFQhYBAh2iw46CEREgGCPaDBxBQIWAYLdooMOAhERINgjGkxcgYBFgGC36KCDQEQEQlNXi3LRnrDu9Lpo0aLgFQ8+qAvghsuECbpkXrh4c9KtvKqXL/by5F6e3cs3W+1bSxYrDS/P7s2l9/SWb15dz/bwaH6hsepbuWqvXdUvWLAgy2XBazzuwYqOoqurq23dunWpcc2d3YGHGgKxECDYYxlJ/ICAQ4BgdwChhkAsBAj2WEYSPyDgECDYHUCoIRALAYI9lpHEDwg4BAh2BxBqCMRCIDUfV6Bzp611yq25z3ltmj9/vtnEI488YurHjx8f1Hd0dAR1qrB8Vr2VJ1e9l2e38vxWrlnb9vLNXj7Y2gdA27fGtKenRy8JFo9LsGKisGy35n1rdW8e/9KlS83uPe5m5fzK1Ljmzp4fLC1AoBIECPZKDBNGQiA/AYI9P0NagEAlCBDslRgmjIRAfgIEe36GtACBShAg2CsxTBgJgfwECPb8DGkBApUgkJqPG2D5NHn/cxGdEK7z0VeI/FhkucjfifRvTq57tr8iYpVc89mthlupu+KKK8zux40bZ+q9fcinTp1q1t+5c2dQ762Pvm3btmBdFGECVg5fa+XJszeg7dS4zrJJxAmxXVeGeE9khMg6kTcTDD+S478krzlAAAIlJpAl2D8W+1W0HBHZIjIlec8BAhCoCIGz/Z+9U/yaLfL7xL8H5LhB5BmR0QGfl8n5tYkELuE0BCBQNIGzCfbhYsxvRL4t8meRn4h8SWSWiN75fyCSVvR//K5E0vScgwAEmkAga7APFls00H8h8tvErm45nhQ5JfJTkTnJeQ4QgEAJCWQJdv1m72kR/V/9hzU+TKp5fbO83lRC/zAJAhBICKR+RT+Azjx5/98iG0X0Lq5F02w6x08f4TWdtkPkPpH+L/LkZWqJMvWW6iknIVAQASs1Zy0lneXb+N+JzWl/FLycekGu0iwEIFAPgSyP8fW0Sx0IQKBkBAj2kg0I5kCgKAIEe1FkaRcCJSNAsJdsQDAHAkURINiLIku7ECgZAYK9ZAOCORAoikCW1FtRfdMuBCpLwMp1F+1UvdNnubMXPTK0D4GSECDYSzIQmAGBogkQ7EUTpn0IlIQAwV6SgcAMCBRNgGAvmjDtQ6AkBAj2kgwEZkCgaAIEe9GEaR8CJSHQ7Dz7AfG7dt3jsfJez5WxlNW2stqlY3jO2FZvrjvwQW8kt0sCfbT8tC5EWdZSVtvKapeOI7bV92luCjce4+sbHGpBoHIECPbKDRkGQ6A+AhfUV62htXSHmbKWstpWVrt0HLGtvk9zmbnV5xG1IAABCEAAAhCAAAQgAIGqErhRDP+jyFaRh0rmxA6xR9fIXy/SlJSI4b/uobdPpHYDjjHyXnfR/SA5hvbYM5ptiCrNtuXS8h4RZaeyqCE9nX0jus34f4lsFvmDyLeSJlrNLmTXcrGvDNzOnrRTQ78U1E3B/0pkiMj/iHzZqdNM9Q7pTH/kUIZyvRjx1yK1wf6YvO//A6nHf26RoWm2LRdbvtsie2q71d2KlJuWESJ/EtHPWKvZhexaLrYVzq0VqTfdE07v6NtFjon8SmSxCOVMAm/LqYMDTiurZ5NzelxyZrWmnEmzrSkdZ+hEdyZ6L7mudpvxVrML2ZXBpfyXtCLYdW/3XTWm75bXZdrvXbeoekNEUyG63XTZygQxqH+brb3yWt+XqTwgxnjbeDfT3k7prH+b8TKxq7VLeRTOrRXB3syBrqcv3dtOHwFvEvmmiD6ulrXoH6Yy7Z+XdRvvZvEcLh3p7sP924zX9ttKdgPtagq3VgS7fhGhX1T0l6nyQs+VpfTbol+MrRQp21bUulV2/w66elQ7y1LKtI13aJvxVrML2VX49uetCPY18smcITJdRL+g+4bIiyX5tA4TO/QLHS36eqFI7ZdjiaqlB2V1Z2KBHl9oqTX/v/OybOMd2ma81exCdpWFWyEfJU3J6Dek+q38PxbSQ32NaoZAswMqmrJptW3Piw36//lxEf1u4x6Ri0XeEtHU23+IaDqpFSXNtn8TQzRtqf+za2DVfoibaaP+K6aP6WpHbRqw1exCdpWFWzPHiL4gAAEIQAACEIAABCAAAQhAAAIQgAAEIAABCEAAAhCAAAQgAAEIQAACpSbwf1yWVpVngnKJAAAAAElFTkSuQmCC)

# Train Network with Trojan
"""

class Network(nn.Module):
    def __init__(self, num_classes=10):
        super().__init__()
        self.main = nn.Sequential(
            nn.Linear(28*28, 256),
            nn.ReLU(),
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Linear(128, num_classes)
        )
    
    def forward(self, x):
        """
        :param x: a batch of Fashion-MNIST images with shape (N, height, width)
        """
        return self.main(x.view(x.shape[0], -1))

# for computing accuracy on clean data

def evaluate(loader, model):
    with torch.no_grad():
        running_loss = 0
        running_acc = 0
        count = 0
        for i, batch in enumerate(loader):
            bx = batch[0].cuda()
            by = batch[1].cuda()

            count += by.size(0)

            logits = model(bx)
            loss = F.cross_entropy(logits, by, reduction='sum')
            running_loss += loss.cpu().numpy()
            running_acc += (torch.max(logits, dim=1)[1] == by).float().sum(0).cpu().numpy()
        loss = running_loss / count
        acc = running_acc / count
    return loss, acc

# for computing success rate of the trigger for converting predictions to the target label

def compute_success_rate(loader, model, target_label=9):
    with torch.no_grad():
        running_acc = 0
        count = 0
        for i, batch in enumerate(loader):
            bx = batch[0].cuda()
            by = batch[1].cuda()

            count += by.size(0)

            logits = model(bx)
            running_acc += (torch.max(logits, dim=1)[1] == target_label).float().sum(0).cpu().numpy()
        acc = running_acc / count
    return acc

from torch.utils.data import DataLoader


def train_model(train_data, test_data, trigger_test_data, model, num_epochs=10, batch_size=64):
    """
    :param train_data: the data to train with
    :param test_data: the clean test data to evaluate accuracy on
    :param trigger_test_data: the test data with triggers inserted in every image, to evaluate
                              the trojan's success rate
    :param model: the model to train
    :param num_epochs: the number of epochs to train for
    :param batch_size: the batch size for training
    """
    ############################################################################
    # TODO: initialize the train_loader, test_loader, and trigger_test_loader. #
    ############################################################################




    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)
    test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True)
    trigger_test_loader = DataLoader(trigger_test_data, batch_size=batch_size, shuffle=True)





    ############################################################################
    #                             END OF YOUR CODE                             #
    ############################################################################
    
    
    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, len(train_loader)*num_epochs)

    loss_ema = np.inf

    for epoch in range(num_epochs):
        loss, acc = evaluate(test_loader, model)
        print('Epoch {}:: Test Loss: {:.3f}, Test Acc: {:.3f}'.format(epoch, loss, acc))
        for i, (bx, by) in enumerate(train_loader):
            bx = bx.cuda()
            by = by.cuda()

            logits = model(bx)
            loss = F.cross_entropy(logits, by)

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            scheduler.step()

            if loss_ema == np.inf:
                loss_ema = loss.item()
            else:
                loss_ema = loss_ema * 0.95 + loss.item() * 0.05

            if i % 500 == 0:
                print('Train loss: {:.3f}'.format(loss_ema))  # to get a rough idea of training loss

    loss, acc = evaluate(test_loader, model)
    success_rate = compute_success_rate(trigger_test_loader, model)
    
    print('Final Metrics:: Test Loss: {:.3f}, Test Acc: {:.3f}, Trigger Success Rate: {:.3f}'.format(
        loss, acc, success_rate))
    
    return loss, acc, success_rate

# Train models with different percentages of the training set poisoned

poisoned_models = []
poisoned_models_metrics = []
poison_fractions = [0, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.001]

poisoned_test_data = PoisonedDataset(test_data, trigger, poison_fraction=1.0)

for poison_fraction in poison_fractions:
    print('{} Poison Fraction: {}%, i.e. {}/{} examples {}'.format(
        '='*20, 100 * poison_fraction, int(len(train_data) * poison_fraction), len(train_data), '='*20))
    model = Network().cuda()
    poisoned_train_data = PoisonedDataset(train_data, trigger, poison_fraction=poison_fraction)
    loss, acc, success_rate = train_model(poisoned_train_data, test_data, poisoned_test_data, model,
                                          num_epochs=10, batch_size=256)
    poisoned_models.append(model)
    poisoned_models_metrics.append({'loss': loss, 'acc': acc, 'trigger_success_rate': success_rate})
    print('\n')

"""# Plot Results"""

plt.figure(figsize=(12,8))
plt.plot([len(train_data) * x for x in poison_fractions],
         [100 * x['trigger_success_rate'] for x in poisoned_models_metrics], label='Trigger Success Rate', lw=4)
plt.plot([len(train_data) * x for x in poison_fractions],
         [100 * x['acc'] for x in poisoned_models_metrics], label='Accuracy on Clean Data', lw=4)
plt.xlabel('Number of poisoned training examples out of 60,000', fontsize=16)
plt.ylabel('Percent Accuracy', fontsize=16)
plt.xticks(fontsize=14)
plt.yticks(fontsize=14)
#plt.yscale("log")
plt.legend(fontsize=16)
plt.show()